{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport glob\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dropout , Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Flatten\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.keras.backend as K\nfrom sklearn.utils import shuffle\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_para = []\nY_para = []\nmyfiles = glob.glob(\"../input/cell_images/cell_images/Parasitized/*.png\")\nfor file in myfiles:\n    kernel = np.array([[0,-1,0],[-1,6,-1],[0,-1,0]])\n    img = cv2.filter2D( cv2.resize(cv2.imread(file) , (120,120)) , -1 , kernel)\n    image_yuv = cv2.cvtColor(img ,cv2.COLOR_BGR2YUV )\n    image_yuv[: ,: , 0] = cv2.equalizeHist(image_yuv[:,:,0])\n    image = cv2.cvtColor(image_yuv , cv2.COLOR_YUV2RGB)\n    X_para.append(image)\n    Y_para.append(1)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_un , Y_un = [],[]\nunfiles = glob.glob(\"../input/cell_images/cell_images/Uninfected/*.png\")\nfor file in unfiles:\n    kernel = np.array([[0,-1,0],[-1,7,-1],[0,-1,0]])\n    img = cv2.filter2D( cv2.resize(cv2.imread(file) , (120,120)) , -1 , kernel)\n    X_un.append(img)\n    Y_un.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_para + X_un\nY = Y_para + Y_un\nX,Y = shuffle = (X,Y)\nX,Y = shuffle = (X,Y)\nX,Y = shuffle = (X,Y)\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3 , random_state =42)\nX = np.array(X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Size","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size=[120,120,3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape = (120 , 120 , 3))\nx = Conv2D(filters = 16 , kernel_size = (3,3) , strides = (1,1) , padding = \"valid\" , kernel_initializer=glorot_uniform(seed = 2))(inp)\nx = Activation(\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters = 32 , kernel_size = (4,4) , strides = (2,2) , padding = \"valid\" , kernel_initializer=glorot_uniform(seed = 2))(x)\nx = Activation(\"relu\")(x)\nx = MaxPooling2D(pool_size = (2,2) , strides = (2,2) , padding = \"valid\")(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters = 64 , kernel_size = (3,3) , strides = (2,2) , padding = \"valid\" , kernel_initializer = glorot_uniform(seed = 2))(x)\nx = Activation(\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters = 128 , kernel_size = (3,3) , strides = (1,1) , padding = \"valid\" , kernel_initializer = glorot_uniform())(x)\nx = Activation(\"relu\")(x)\nx = MaxPooling2D(pool_size = (2,2) , strides = (2,2) , padding = \"valid\")(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters = 256 , kernel_size = (2,2) , strides = (2,2) , padding = \"valid\" , kernel_initializer = glorot_uniform())(x)\nx = Activation(\"relu\")(x)\nx = AveragePooling2D(pool_size = (3,3) , strides = (1,1) , padding = \"valid\")(x)\nx = Dropout(0.2)(x)\nx = Flatten()(x)\nx = Dense(120)(x)\nx = Activation(\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(60)(x)\nx = Activation(\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(10)(x)\nx = Activation(\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(1)(x)\noutput = Activation(\"sigmoid\")(x)\nmodel  = Model(inputs =inp , outputs = output )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = \"binary_crossentropy\" , optimizer = \"adam\" , metrics = [\"accuracy\"])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(np.array(X_train) ,np.array(Y_train) , epochs = 13 ,validation_split = 0.2 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives output in 2d array\ny_pre = model.predict(np.array(X_test))\n# converting 2d array into 1d arrray\ny_pre = np.reshape(y_pre ,(8268,) )\nprint(y_pre)\n\nY_test = np.array(Y_test)\nfil = y_pre > 0.8\ny_pre[fil] = 1\nfil = y_pre < 0.8\ny_pre[fil] = 0\n\n# printing accuracy of th test dataset\nnp.sum(Y_test == y_pre)/8268","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(Y_test,y_pre))\nprint(accuracy_score(Y_test,y_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting Accuracy plot of training and validation accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history[\"val_acc\"])\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting loss of training and validation dataset\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG 19","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the pre_trained model\npre_trained_model = tf.keras.applications.VGG19(input_shape=(120,120,3),include_top=False,weights='imagenet')\n\n# we want to keep some weights as it is so let's lock above layers of the Network\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n    \npre_trained_model.summary()\n\nx = Flatten()(pre_trained_model.output)\n\nx = Dense(1,activation='sigmoid')(x)\n\nVGG19_model = Model(pre_trained_model.input,x)\n\nVGG19_model.compile(optimizer = 'adam',loss = 'binary_crossentropy', \n              metrics = ['accuracy'])\n\nhistory = VGG19_model.fit(np.array(X_train) ,np.array(Y_train) , epochs = 10 ,validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives output in 2d array\ny_pre = VGG19_model.predict(np.array(X_test))\n# converting 2d array into 1d arrray\ny_pre_vgg19 = np.reshape(y_pre ,(8268,) )\nprint(y_pre_vgg19)\n\nY_test = np.array(Y_test)\nfil = y_pre_vgg19 > 0.8\ny_pre_vgg19[fil] = 1\nfil = y_pre_vgg19 < 0.8\ny_pre_vgg19[fil] = 0\n\n# printing accuracy of th test dataset\nnp.sum(Y_test == y_pre_vgg19)/8268","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(Y_test,y_pre_vgg19))\nprint(accuracy_score(Y_test,y_pre_vgg19))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting Accuracy plot of training and validation accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history[\"val_acc\"])\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting loss of training and validation dataset\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG 16","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the pre_trained model\npre_trained_model = tf.keras.applications.VGG16(input_shape=(120,120,3),include_top=False,weights='imagenet')\n\n# we want to keep some weights as it is so let's lock above layers of the Network\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n    \npre_trained_model.summary()\n\nx = Flatten()(pre_trained_model.output)\n\nx = Dense(1,activation='sigmoid')(x)\n\nVGG16_model = Model(pre_trained_model.input,x)\n\nVGG16_model.compile(optimizer = 'adam',loss = 'binary_crossentropy', \n              metrics = ['accuracy'])\n\nhistory = VGG16_model.fit(np.array(X_train) ,np.array(Y_train) , epochs = 10 ,validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives output in 2d array\ny_pre = VGG16_model.predict(np.array(X_test))\n# converting 2d array into 1d arrray\ny_pre_vgg16 = np.reshape(y_pre ,(8268,) )\nprint(y_pre_vgg16)\n\nY_test = np.array(Y_test)\nfil = y_pre_vgg16 > 0.8\ny_pre_vgg16[fil] = 1\nfil = y_pre_vgg16 < 0.8\ny_pre_vgg16[fil] = 0\n\n# printing accuracy of th test dataset\nnp.sum(Y_test == y_pre_vgg16)/8268","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(Y_test,y_pre_vgg16))\nprint(accuracy_score(Y_test,y_pre_vgg16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting Accuracy plot of training and validation accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history[\"val_acc\"])\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting loss of training and validation dataset\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DenseNet 121","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Flatten, Dropout, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint   \nfrom tensorflow.keras.utils import to_categorical\n\n\nY_train = to_categorical(Y_train)\n\nY_test = to_categorical(Y_test)\n\nconv_base = DenseNet121(weights=\"imagenet\", include_top = False, input_shape=(120,120,3))\n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\nmodel.summary()\n\n# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit(\n    np.array(X_train),np.array(Y_train),\n    batch_size=64,\n    epochs=10,\n    callbacks=[checkpoint],\n    validation_split=0.2,\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives output in 2d array\ny_pre_dense = model.predict(np.array(X_test))\n# converting 2d array into 1d arrray\n\nY_test = np.array(Y_test)\nfil = y_pre_dense > 0.8\ny_pre_dense[fil] = 1\nfil = y_pre_dense < 0.8\ny_pre_dense[fil] = 0\n\n# printing accuracy of th test dataset\nnp.sum(Y_test == y_pre_dense)/8268","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(Y_test,y_pre_dense))\nprint(accuracy_score(Y_test,y_pre_dense))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting Accuracy plot of training and validation accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history[\"val_acc\"])\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Accuracy\")\nplt.ylabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting loss of training and validation dataset\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Embedding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pre_dense = y_pre_dense[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = Y_test[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final = []\nfor i in range(len(y_pre_dense)):\n    if(y_pre_vgg16[i] == y_pre[i]):\n        y_final.append(y_pre_vgg16[i])\n    elif(y_pre_vgg16[i] == y_pre_dense[i]):\n        y_final.append(y_pre_vgg16[i])\n    elif(y_pre[i] == y_pre_dense[i]):\n        y_final.append(y_pre_vgg19[i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final = np.array(y_final)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(Y_test,y_final))\nprint(accuracy_score(Y_test,y_final))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}